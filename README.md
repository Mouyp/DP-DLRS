# DP-DLRS

This project aims to explore and employ the concept of differential privacy, a noise-infusion technique that ensures rigorous privacy protection, to examine its influence on the performance of deep learning models. As the noise injection affect the model performance, the study navigates the inherent tension between data privacy and the utility trade-off. 

The impact of differential privacy on the accuracy of recommendations is evaluated across a wide range of privacy budgets, from low to high epsilon values, in Collaborative Filtering Recommender Systems utilizing the MovieLens 1M dataset.
